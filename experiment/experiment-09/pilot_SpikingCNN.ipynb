{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3f43935c-06eb-44d7-ac05-ea507af42ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "#from snntorch import backprop\n",
    "from snntorch import functional as SF\n",
    "from snntorch import utils\n",
    "from snntorch import spikeplot as splt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "981d1f70-ada8-485e-b9b3-a9633e9a9a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_steps, beta, spike_grad, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize Attributes\n",
    "        self.num_steps = num_steps\n",
    "        \n",
    "        # Initialize layers\n",
    "        self.conv1 = nn.Conv2d(3, 12, 5)\n",
    "        self.bn1 = nn.BatchNorm2d(12)\n",
    "        self.lif1 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(12, 64, 5)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.lif2 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.fc1 = nn.Linear(64*5*5, 10)\n",
    "        self.bn3 = nn.BatchNorm1d(10)\n",
    "        self.lif3 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
    "\n",
    "    def recursive_forward(self, cur, mem, net, num_steps):\n",
    "        spk_rec = []\n",
    "        mem_rec = []\n",
    "        utils.reset(net)\n",
    "        for step in range(num_steps):\n",
    "            spk, mem = net(cur)\n",
    "            spk_rec.append(spk)\n",
    "            mem_rec.append(mem)\n",
    "        return torch.stack(spk_rec), torch.stack(mem_rec)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        # Initialize hidden states and outputs at t=0\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        mem3 = self.lif3.init_leaky()\n",
    "\n",
    "        cur1 = F.max_pool2d(self.bn1(self.conv1(x)), 2)\n",
    "        #spk1, mem1 = self.lif1(cur1, mem1)\n",
    "        spk1, mem1 = self.recursive_forward(cur1, mem1, self.lif1, self.num_steps)\n",
    "        spk1 = torch.mean(spk1, dim=0)\n",
    "\n",
    "        cur2 = F.max_pool2d(self.bn2(self.conv2(spk1)), 2)\n",
    "        #spk2, mem2 = self.lif2(cur2, mem2)\n",
    "        spk2, mem2 = self.recursive_forward(cur2, mem2, self.lif2, self.num_steps)\n",
    "        spk2 = torch.mean(spk2, dim=0)\n",
    "\n",
    "        cur3 = self.dropout(spk2.view(spk2.shape[0], -1))\n",
    "        cur3 = self.fc1(cur3)\n",
    "\n",
    "        cur3 = self.bn3(cur3)\n",
    "        #spk3, mem3 = self.lif3(cur3, mem3)\n",
    "        spk3, mem3 = self.recursive_forward(cur3, mem3, self.lif3, self.num_steps)\n",
    "\n",
    "        return spk3, mem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "87e3fd1f-e6a6-4e09-af9e-7b3679b28f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNormalize:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, data):\n",
    "        vmax, vmin = data.max(), data.min()\n",
    "        return (data-vmin)/(vmax-vmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dc73d9b9-a6c1-47ee-9998-9dad15947857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(net, num_steps, data):\n",
    "  mem_rec = []\n",
    "  spk_rec = []\n",
    "  utils.reset(net)  # resets hidden states for all LIF neurons in net\n",
    "\n",
    "  for step in range(num_steps):\n",
    "      spk_out, mem_out = net(data)\n",
    "      spk_rec.append(spk_out)\n",
    "      mem_rec.append(mem_out)\n",
    "\n",
    "  return torch.stack(spk_rec), torch.stack(mem_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "92a9a887-8389-4564-b1a8-fa7f59f83139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(train_loader, net, num_steps):\n",
    "  with torch.no_grad():\n",
    "    total = 0\n",
    "    acc = 0\n",
    "    net.eval()\n",
    "\n",
    "    train_loader = iter(train_loader)\n",
    "    for data, targets in train_loader:\n",
    "      data = data.to(device)\n",
    "      targets = targets.to(device)\n",
    "      #spk_rec, _ = forward_pass(net, num_steps, data)\n",
    "      spk_rec, _ = net(data)\n",
    "\n",
    "      acc += SF.accuracy_rate(spk_rec, targets) * spk_rec.size(1)\n",
    "      total += spk_rec.size(1)\n",
    "\n",
    "  return acc/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e30f476c-2af1-43e1-83bd-759da403dd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), MyNormalize()])\n",
    "train_dataset = datasets.CIFAR10(root='/home/hwkang/jupyter/root/dataset', train=True, transform=transform, download=False)\n",
    "test_dataset = datasets.CIFAR10(root='/home/hwkang/jupyter/root/dataset', train=False, transform=transform, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0b4b9b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2d345eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 훈련 데이터셋과 검증 데이터셋으로 분할\n",
    "dataset_size = len(train_dataset)\n",
    "train_size = int(0.9 * dataset_size)\n",
    "valid_size = dataset_size - train_size\n",
    "train_dataset, valid_dataset = random_split(train_dataset, [train_size, valid_size])\n",
    "##*\n",
    "\n",
    "### 데이터로더 준비\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "97c56a2b-de8c-445a-9571-3cc89fc1e56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2692d40a-e245-404c-8360-b53e3015b8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps=50\n",
    "\n",
    "# Model\n",
    "net = Net(num_steps=num_steps, beta=0.9, spike_grad=surrogate.atan())\n",
    "net = net.to(device)\n",
    "\n",
    "# Epoch\n",
    "num_epochs = 50\n",
    "\n",
    "# Loss func.\n",
    "loss_fn_rate = SF.ce_rate_loss()\n",
    "\n",
    "# Optim.\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3, betas=(0.9, 0.999))\n",
    "\n",
    "# Util.\n",
    "loss_hist = []\n",
    "test_acc_hist = []\n",
    "counter = 0\n",
    "min_acc = 0.0\n",
    "best_acc_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "87db5fc3-7ff7-4e27-80d4-1854a8d3345e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50 | Iter.: 0 | Acc.: 9.74%\n",
      "Epoch: 1/50 | Iter.: 100 | Acc.: 31.08%\n",
      "Epoch: 1/50 | Iter.: 200 | Acc.: 35.54%\n",
      "Epoch: 1/50 | Iter.: 300 | Acc.: 35.12%\n",
      "Epoch: 1/50 | Iter.: 400 | Acc.: 35.54%\n",
      "Epoch: 1/50 | Iter.: 500 | Acc.: 40.08%\n",
      "Epoch: 1/50 | Iter.: 600 | Acc.: 37.18%\n",
      "Epoch: 1/50 | Iter.: 700 | Acc.: 35.62%\n",
      "Epoch: 2/50 | Iter.: 800 | Acc.: 36.26%\n",
      "Epoch: 2/50 | Iter.: 900 | Acc.: 43.06%\n",
      "Epoch: 2/50 | Iter.: 1000 | Acc.: 34.22%\n",
      "Epoch: 2/50 | Iter.: 1100 | Acc.: 42.14%\n",
      "Epoch: 2/50 | Iter.: 1200 | Acc.: 32.42%\n",
      "Epoch: 2/50 | Iter.: 1300 | Acc.: 40.02%\n",
      "Epoch: 2/50 | Iter.: 1400 | Acc.: 40.58%\n",
      "Epoch: 3/50 | Iter.: 1500 | Acc.: 38.36%\n",
      "Epoch: 3/50 | Iter.: 1600 | Acc.: 41.26%\n",
      "Epoch: 3/50 | Iter.: 1700 | Acc.: 40.10%\n",
      "Epoch: 3/50 | Iter.: 1800 | Acc.: 40.10%\n",
      "Epoch: 3/50 | Iter.: 1900 | Acc.: 47.00%\n",
      "Epoch: 3/50 | Iter.: 2000 | Acc.: 47.84%\n",
      "Epoch: 3/50 | Iter.: 2100 | Acc.: 43.12%\n",
      "Epoch: 4/50 | Iter.: 2200 | Acc.: 47.14%\n",
      "Epoch: 4/50 | Iter.: 2300 | Acc.: 46.20%\n",
      "Epoch: 4/50 | Iter.: 2400 | Acc.: 46.16%\n",
      "Epoch: 4/50 | Iter.: 2500 | Acc.: 49.24%\n",
      "Epoch: 4/50 | Iter.: 2600 | Acc.: 40.28%\n",
      "Epoch: 4/50 | Iter.: 2700 | Acc.: 47.30%\n",
      "Epoch: 4/50 | Iter.: 2800 | Acc.: 41.22%\n",
      "Epoch: 5/50 | Iter.: 2900 | Acc.: 45.32%\n",
      "Epoch: 5/50 | Iter.: 3000 | Acc.: 49.40%\n",
      "Epoch: 5/50 | Iter.: 3100 | Acc.: 49.50%\n",
      "Epoch: 5/50 | Iter.: 3200 | Acc.: 50.02%\n",
      "Epoch: 5/50 | Iter.: 3300 | Acc.: 50.28%\n",
      "Epoch: 5/50 | Iter.: 3400 | Acc.: 49.52%\n",
      "Epoch: 5/50 | Iter.: 3500 | Acc.: 47.88%\n",
      "Epoch: 6/50 | Iter.: 3600 | Acc.: 47.78%\n",
      "Epoch: 6/50 | Iter.: 3700 | Acc.: 53.90%\n",
      "Epoch: 6/50 | Iter.: 3800 | Acc.: 42.44%\n",
      "Epoch: 6/50 | Iter.: 3900 | Acc.: 49.72%\n",
      "Epoch: 6/50 | Iter.: 4000 | Acc.: 54.26%\n",
      "Epoch: 6/50 | Iter.: 4100 | Acc.: 47.64%\n",
      "Epoch: 6/50 | Iter.: 4200 | Acc.: 48.18%\n",
      "Epoch: 7/50 | Iter.: 4300 | Acc.: 55.44%\n",
      "Epoch: 7/50 | Iter.: 4400 | Acc.: 54.92%\n",
      "Epoch: 7/50 | Iter.: 4500 | Acc.: 50.60%\n",
      "Epoch: 7/50 | Iter.: 4600 | Acc.: 51.50%\n",
      "Epoch: 7/50 | Iter.: 4700 | Acc.: 54.36%\n",
      "Epoch: 7/50 | Iter.: 4800 | Acc.: 48.16%\n",
      "Epoch: 7/50 | Iter.: 4900 | Acc.: 53.16%\n",
      "Epoch: 8/50 | Iter.: 5000 | Acc.: 53.68%\n",
      "Epoch: 8/50 | Iter.: 5100 | Acc.: 53.60%\n",
      "Epoch: 8/50 | Iter.: 5200 | Acc.: 55.36%\n",
      "Epoch: 8/50 | Iter.: 5300 | Acc.: 44.72%\n",
      "Epoch: 8/50 | Iter.: 5400 | Acc.: 52.10%\n",
      "Epoch: 8/50 | Iter.: 5500 | Acc.: 51.12%\n",
      "Epoch: 8/50 | Iter.: 5600 | Acc.: 52.48%\n",
      "Epoch: 9/50 | Iter.: 5700 | Acc.: 55.02%\n",
      "Epoch: 9/50 | Iter.: 5800 | Acc.: 45.54%\n",
      "Epoch: 9/50 | Iter.: 5900 | Acc.: 53.60%\n",
      "Epoch: 9/50 | Iter.: 6000 | Acc.: 58.70%\n",
      "Epoch: 9/50 | Iter.: 6100 | Acc.: 58.40%\n",
      "Epoch: 9/50 | Iter.: 6200 | Acc.: 55.04%\n",
      "Epoch: 9/50 | Iter.: 6300 | Acc.: 57.06%\n",
      "Epoch: 10/50 | Iter.: 6400 | Acc.: 50.36%\n",
      "Epoch: 10/50 | Iter.: 6500 | Acc.: 54.32%\n",
      "Epoch: 10/50 | Iter.: 6600 | Acc.: 52.94%\n",
      "Epoch: 10/50 | Iter.: 6700 | Acc.: 49.48%\n",
      "Epoch: 10/50 | Iter.: 6800 | Acc.: 50.48%\n",
      "Epoch: 10/50 | Iter.: 6900 | Acc.: 56.58%\n",
      "Epoch: 10/50 | Iter.: 7000 | Acc.: 58.46%\n",
      "Epoch: 11/50 | Iter.: 7100 | Acc.: 56.66%\n",
      "Epoch: 11/50 | Iter.: 7200 | Acc.: 57.18%\n",
      "Epoch: 11/50 | Iter.: 7300 | Acc.: 58.20%\n",
      "Epoch: 11/50 | Iter.: 7400 | Acc.: 56.02%\n",
      "Epoch: 11/50 | Iter.: 7500 | Acc.: 49.66%\n",
      "Epoch: 11/50 | Iter.: 7600 | Acc.: 57.36%\n",
      "Epoch: 11/50 | Iter.: 7700 | Acc.: 57.38%\n",
      "Epoch: 12/50 | Iter.: 7800 | Acc.: 55.66%\n",
      "Epoch: 12/50 | Iter.: 7900 | Acc.: 50.18%\n",
      "Epoch: 12/50 | Iter.: 8000 | Acc.: 49.70%\n",
      "Epoch: 12/50 | Iter.: 8100 | Acc.: 54.62%\n",
      "Epoch: 12/50 | Iter.: 8200 | Acc.: 57.54%\n",
      "Epoch: 12/50 | Iter.: 8300 | Acc.: 58.96%\n",
      "Epoch: 12/50 | Iter.: 8400 | Acc.: 53.66%\n",
      "Epoch: 13/50 | Iter.: 8500 | Acc.: 55.74%\n",
      "Epoch: 13/50 | Iter.: 8600 | Acc.: 55.64%\n",
      "Epoch: 13/50 | Iter.: 8700 | Acc.: 51.60%\n",
      "Epoch: 13/50 | Iter.: 8800 | Acc.: 52.20%\n",
      "Epoch: 13/50 | Iter.: 8900 | Acc.: 53.82%\n",
      "Epoch: 13/50 | Iter.: 9000 | Acc.: 46.72%\n",
      "Epoch: 13/50 | Iter.: 9100 | Acc.: 58.42%\n",
      "Epoch: 14/50 | Iter.: 9200 | Acc.: 57.06%\n",
      "Epoch: 14/50 | Iter.: 9300 | Acc.: 54.04%\n",
      "Epoch: 14/50 | Iter.: 9400 | Acc.: 57.06%\n",
      "Epoch: 14/50 | Iter.: 9500 | Acc.: 56.14%\n",
      "Epoch: 14/50 | Iter.: 9600 | Acc.: 53.36%\n",
      "Epoch: 14/50 | Iter.: 9700 | Acc.: 54.58%\n",
      "Epoch: 14/50 | Iter.: 9800 | Acc.: 59.88%\n",
      "Epoch: 15/50 | Iter.: 9900 | Acc.: 57.74%\n",
      "Epoch: 15/50 | Iter.: 10000 | Acc.: 58.12%\n",
      "Epoch: 15/50 | Iter.: 10100 | Acc.: 50.64%\n",
      "Epoch: 15/50 | Iter.: 10200 | Acc.: 55.68%\n",
      "Epoch: 15/50 | Iter.: 10300 | Acc.: 59.32%\n",
      "Epoch: 15/50 | Iter.: 10400 | Acc.: 59.28%\n",
      "Epoch: 15/50 | Iter.: 10500 | Acc.: 57.82%\n",
      "Epoch: 16/50 | Iter.: 10600 | Acc.: 59.26%\n",
      "Epoch: 16/50 | Iter.: 10700 | Acc.: 52.56%\n",
      "Epoch: 16/50 | Iter.: 10800 | Acc.: 60.56%\n",
      "Epoch: 16/50 | Iter.: 10900 | Acc.: 60.52%\n",
      "Epoch: 16/50 | Iter.: 11000 | Acc.: 51.28%\n",
      "Epoch: 16/50 | Iter.: 11100 | Acc.: 59.70%\n",
      "Epoch: 16/50 | Iter.: 11200 | Acc.: 58.58%\n",
      "Epoch: 17/50 | Iter.: 11300 | Acc.: 60.18%\n",
      "Epoch: 17/50 | Iter.: 11400 | Acc.: 58.26%\n",
      "Epoch: 17/50 | Iter.: 11500 | Acc.: 60.74%\n",
      "Epoch: 17/50 | Iter.: 11600 | Acc.: 52.30%\n",
      "Epoch: 17/50 | Iter.: 11700 | Acc.: 58.58%\n",
      "Epoch: 17/50 | Iter.: 11800 | Acc.: 61.32%\n",
      "Epoch: 17/50 | Iter.: 11900 | Acc.: 56.36%\n",
      "Epoch: 18/50 | Iter.: 12000 | Acc.: 54.50%\n",
      "Epoch: 18/50 | Iter.: 12100 | Acc.: 56.54%\n",
      "Epoch: 18/50 | Iter.: 12200 | Acc.: 57.60%\n",
      "Epoch: 18/50 | Iter.: 12300 | Acc.: 59.90%\n",
      "Epoch: 18/50 | Iter.: 12400 | Acc.: 57.50%\n",
      "Epoch: 18/50 | Iter.: 12500 | Acc.: 60.96%\n",
      "Epoch: 18/50 | Iter.: 12600 | Acc.: 60.10%\n",
      "Epoch: 19/50 | Iter.: 12700 | Acc.: 57.38%\n",
      "Epoch: 19/50 | Iter.: 12800 | Acc.: 60.62%\n",
      "Epoch: 19/50 | Iter.: 12900 | Acc.: 58.52%\n",
      "Epoch: 19/50 | Iter.: 13000 | Acc.: 62.30%\n",
      "Epoch: 19/50 | Iter.: 13100 | Acc.: 57.34%\n",
      "Epoch: 19/50 | Iter.: 13200 | Acc.: 61.12%\n",
      "Epoch: 19/50 | Iter.: 13300 | Acc.: 56.78%\n",
      "Epoch: 20/50 | Iter.: 13400 | Acc.: 60.42%\n",
      "Epoch: 20/50 | Iter.: 13500 | Acc.: 61.74%\n",
      "Epoch: 20/50 | Iter.: 13600 | Acc.: 61.94%\n",
      "Epoch: 20/50 | Iter.: 13700 | Acc.: 56.62%\n",
      "Epoch: 20/50 | Iter.: 13800 | Acc.: 60.92%\n",
      "Epoch: 20/50 | Iter.: 13900 | Acc.: 54.42%\n",
      "Epoch: 20/50 | Iter.: 14000 | Acc.: 59.50%\n",
      "Epoch: 21/50 | Iter.: 14100 | Acc.: 57.42%\n",
      "Epoch: 21/50 | Iter.: 14200 | Acc.: 59.58%\n",
      "Epoch: 21/50 | Iter.: 14300 | Acc.: 57.02%\n",
      "Epoch: 21/50 | Iter.: 14400 | Acc.: 55.26%\n",
      "Epoch: 21/50 | Iter.: 14500 | Acc.: 61.88%\n",
      "Epoch: 21/50 | Iter.: 14600 | Acc.: 55.00%\n",
      "Epoch: 21/50 | Iter.: 14700 | Acc.: 61.18%\n",
      "Epoch: 22/50 | Iter.: 14800 | Acc.: 56.52%\n",
      "Epoch: 22/50 | Iter.: 14900 | Acc.: 61.94%\n",
      "Epoch: 22/50 | Iter.: 15000 | Acc.: 61.32%\n",
      "Epoch: 22/50 | Iter.: 15100 | Acc.: 62.08%\n",
      "Epoch: 22/50 | Iter.: 15200 | Acc.: 51.68%\n",
      "Epoch: 22/50 | Iter.: 15300 | Acc.: 59.20%\n",
      "Epoch: 22/50 | Iter.: 15400 | Acc.: 58.66%\n",
      "Epoch: 23/50 | Iter.: 15500 | Acc.: 59.72%\n",
      "Epoch: 23/50 | Iter.: 15600 | Acc.: 61.96%\n",
      "Epoch: 23/50 | Iter.: 15700 | Acc.: 56.50%\n",
      "Epoch: 23/50 | Iter.: 15800 | Acc.: 63.20%\n",
      "Epoch: 23/50 | Iter.: 15900 | Acc.: 58.78%\n",
      "Epoch: 23/50 | Iter.: 16000 | Acc.: 61.24%\n",
      "Epoch: 23/50 | Iter.: 16100 | Acc.: 54.30%\n",
      "Epoch: 24/50 | Iter.: 16200 | Acc.: 54.96%\n",
      "Epoch: 24/50 | Iter.: 16300 | Acc.: 58.34%\n",
      "Epoch: 24/50 | Iter.: 16400 | Acc.: 56.92%\n",
      "Epoch: 24/50 | Iter.: 16500 | Acc.: 59.88%\n",
      "Epoch: 24/50 | Iter.: 16600 | Acc.: 60.42%\n",
      "Epoch: 24/50 | Iter.: 16700 | Acc.: 55.62%\n",
      "Epoch: 24/50 | Iter.: 16800 | Acc.: 62.80%\n",
      "Epoch: 25/50 | Iter.: 16900 | Acc.: 59.28%\n",
      "Epoch: 25/50 | Iter.: 17000 | Acc.: 61.94%\n",
      "Epoch: 25/50 | Iter.: 17100 | Acc.: 54.08%\n",
      "Epoch: 25/50 | Iter.: 17200 | Acc.: 62.84%\n",
      "Epoch: 25/50 | Iter.: 17300 | Acc.: 56.98%\n",
      "Epoch: 25/50 | Iter.: 17400 | Acc.: 63.34%\n",
      "Epoch: 25/50 | Iter.: 17500 | Acc.: 60.44%\n",
      "Epoch: 26/50 | Iter.: 17600 | Acc.: 61.42%\n",
      "Epoch: 26/50 | Iter.: 17700 | Acc.: 57.74%\n",
      "Epoch: 26/50 | Iter.: 17800 | Acc.: 54.96%\n",
      "Epoch: 26/50 | Iter.: 17900 | Acc.: 62.00%\n",
      "Epoch: 26/50 | Iter.: 18000 | Acc.: 59.24%\n",
      "Epoch: 26/50 | Iter.: 18100 | Acc.: 62.38%\n",
      "Epoch: 26/50 | Iter.: 18200 | Acc.: 58.10%\n",
      "Epoch: 26/50 | Iter.: 18300 | Acc.: 59.30%\n",
      "Epoch: 27/50 | Iter.: 18400 | Acc.: 57.50%\n",
      "Epoch: 27/50 | Iter.: 18500 | Acc.: 61.40%\n",
      "Epoch: 27/50 | Iter.: 18600 | Acc.: 61.20%\n",
      "Epoch: 27/50 | Iter.: 18700 | Acc.: 52.80%\n",
      "Epoch: 27/50 | Iter.: 18800 | Acc.: 61.58%\n",
      "Epoch: 27/50 | Iter.: 18900 | Acc.: 58.66%\n",
      "Epoch: 27/50 | Iter.: 19000 | Acc.: 61.32%\n",
      "Epoch: 28/50 | Iter.: 19100 | Acc.: 59.86%\n",
      "Epoch: 28/50 | Iter.: 19200 | Acc.: 60.26%\n",
      "Epoch: 28/50 | Iter.: 19300 | Acc.: 59.62%\n",
      "Epoch: 28/50 | Iter.: 19400 | Acc.: 62.00%\n",
      "Epoch: 28/50 | Iter.: 19500 | Acc.: 59.30%\n",
      "Epoch: 28/50 | Iter.: 19600 | Acc.: 62.62%\n",
      "Epoch: 28/50 | Iter.: 19700 | Acc.: 59.98%\n",
      "Epoch: 29/50 | Iter.: 19800 | Acc.: 56.76%\n",
      "Epoch: 29/50 | Iter.: 19900 | Acc.: 64.04%\n",
      "Epoch: 29/50 | Iter.: 20000 | Acc.: 61.80%\n",
      "Epoch: 29/50 | Iter.: 20100 | Acc.: 49.72%\n",
      "Epoch: 29/50 | Iter.: 20200 | Acc.: 62.52%\n",
      "Epoch: 29/50 | Iter.: 20300 | Acc.: 62.30%\n",
      "Epoch: 29/50 | Iter.: 20400 | Acc.: 59.76%\n",
      "Epoch: 30/50 | Iter.: 20500 | Acc.: 59.00%\n",
      "Epoch: 30/50 | Iter.: 20600 | Acc.: 61.06%\n",
      "Epoch: 30/50 | Iter.: 20700 | Acc.: 62.08%\n",
      "Epoch: 30/50 | Iter.: 20800 | Acc.: 61.86%\n",
      "Epoch: 30/50 | Iter.: 20900 | Acc.: 53.50%\n",
      "Epoch: 30/50 | Iter.: 21000 | Acc.: 61.00%\n",
      "Epoch: 30/50 | Iter.: 21100 | Acc.: 58.18%\n",
      "Epoch: 31/50 | Iter.: 21200 | Acc.: 58.98%\n",
      "Epoch: 31/50 | Iter.: 21300 | Acc.: 63.84%\n",
      "Epoch: 31/50 | Iter.: 21400 | Acc.: 57.66%\n",
      "Epoch: 31/50 | Iter.: 21500 | Acc.: 62.12%\n",
      "Epoch: 31/50 | Iter.: 21600 | Acc.: 57.90%\n",
      "Epoch: 31/50 | Iter.: 21700 | Acc.: 61.58%\n",
      "Epoch: 31/50 | Iter.: 21800 | Acc.: 62.90%\n",
      "Epoch: 32/50 | Iter.: 21900 | Acc.: 60.50%\n",
      "Epoch: 32/50 | Iter.: 22000 | Acc.: 62.18%\n",
      "Epoch: 32/50 | Iter.: 22100 | Acc.: 58.12%\n",
      "Epoch: 32/50 | Iter.: 22200 | Acc.: 61.82%\n",
      "Epoch: 32/50 | Iter.: 22300 | Acc.: 59.42%\n",
      "Epoch: 32/50 | Iter.: 22400 | Acc.: 60.24%\n",
      "Epoch: 32/50 | Iter.: 22500 | Acc.: 60.90%\n",
      "Epoch: 33/50 | Iter.: 22600 | Acc.: 56.24%\n",
      "Epoch: 33/50 | Iter.: 22700 | Acc.: 64.08%\n",
      "Epoch: 33/50 | Iter.: 22800 | Acc.: 63.54%\n",
      "Epoch: 33/50 | Iter.: 22900 | Acc.: 61.66%\n",
      "Epoch: 33/50 | Iter.: 23000 | Acc.: 57.00%\n",
      "Epoch: 33/50 | Iter.: 23100 | Acc.: 59.46%\n",
      "Epoch: 33/50 | Iter.: 23200 | Acc.: 60.96%\n",
      "Epoch: 34/50 | Iter.: 23300 | Acc.: 62.08%\n",
      "Epoch: 34/50 | Iter.: 23400 | Acc.: 62.38%\n",
      "Epoch: 34/50 | Iter.: 23500 | Acc.: 62.48%\n",
      "Epoch: 34/50 | Iter.: 23600 | Acc.: 63.16%\n",
      "Epoch: 34/50 | Iter.: 23700 | Acc.: 57.42%\n",
      "Epoch: 34/50 | Iter.: 23800 | Acc.: 62.84%\n",
      "Epoch: 34/50 | Iter.: 23900 | Acc.: 60.56%\n",
      "Epoch: 35/50 | Iter.: 24000 | Acc.: 61.82%\n",
      "Epoch: 35/50 | Iter.: 24100 | Acc.: 62.74%\n",
      "Epoch: 35/50 | Iter.: 24200 | Acc.: 63.98%\n",
      "Epoch: 35/50 | Iter.: 24300 | Acc.: 64.16%\n",
      "Epoch: 35/50 | Iter.: 24400 | Acc.: 63.54%\n",
      "Epoch: 35/50 | Iter.: 24500 | Acc.: 55.64%\n",
      "Epoch: 35/50 | Iter.: 24600 | Acc.: 61.92%\n",
      "Epoch: 36/50 | Iter.: 24700 | Acc.: 61.50%\n",
      "Epoch: 36/50 | Iter.: 24800 | Acc.: 65.18%\n",
      "Epoch: 36/50 | Iter.: 24900 | Acc.: 62.14%\n",
      "Epoch: 36/50 | Iter.: 25000 | Acc.: 59.14%\n",
      "Epoch: 36/50 | Iter.: 25100 | Acc.: 62.10%\n",
      "Epoch: 36/50 | Iter.: 25200 | Acc.: 56.04%\n",
      "Epoch: 36/50 | Iter.: 25300 | Acc.: 63.34%\n",
      "Epoch: 37/50 | Iter.: 25400 | Acc.: 57.88%\n",
      "Epoch: 37/50 | Iter.: 25500 | Acc.: 60.76%\n",
      "Epoch: 37/50 | Iter.: 25600 | Acc.: 63.84%\n",
      "Epoch: 37/50 | Iter.: 25700 | Acc.: 63.18%\n",
      "Epoch: 37/50 | Iter.: 25800 | Acc.: 61.86%\n",
      "Epoch: 37/50 | Iter.: 25900 | Acc.: 62.58%\n",
      "Epoch: 37/50 | Iter.: 26000 | Acc.: 63.52%\n",
      "Epoch: 38/50 | Iter.: 26100 | Acc.: 61.28%\n",
      "Epoch: 38/50 | Iter.: 26200 | Acc.: 58.82%\n",
      "Epoch: 38/50 | Iter.: 26300 | Acc.: 62.60%\n",
      "Epoch: 38/50 | Iter.: 26400 | Acc.: 62.22%\n",
      "Epoch: 38/50 | Iter.: 26500 | Acc.: 62.86%\n",
      "Epoch: 38/50 | Iter.: 26600 | Acc.: 57.40%\n",
      "Epoch: 38/50 | Iter.: 26700 | Acc.: 61.86%\n",
      "Epoch: 39/50 | Iter.: 26800 | Acc.: 62.14%\n",
      "Epoch: 39/50 | Iter.: 26900 | Acc.: 62.14%\n",
      "Epoch: 39/50 | Iter.: 27000 | Acc.: 63.90%\n",
      "Epoch: 39/50 | Iter.: 27100 | Acc.: 62.42%\n",
      "Epoch: 39/50 | Iter.: 27200 | Acc.: 62.70%\n",
      "Epoch: 39/50 | Iter.: 27300 | Acc.: 64.96%\n",
      "Epoch: 39/50 | Iter.: 27400 | Acc.: 61.44%\n",
      "Epoch: 40/50 | Iter.: 27500 | Acc.: 61.54%\n",
      "Epoch: 40/50 | Iter.: 27600 | Acc.: 61.98%\n",
      "Epoch: 40/50 | Iter.: 27700 | Acc.: 60.46%\n",
      "Epoch: 40/50 | Iter.: 27800 | Acc.: 59.24%\n",
      "Epoch: 40/50 | Iter.: 27900 | Acc.: 63.16%\n",
      "Epoch: 40/50 | Iter.: 28000 | Acc.: 60.74%\n",
      "Epoch: 40/50 | Iter.: 28100 | Acc.: 63.64%\n",
      "Epoch: 41/50 | Iter.: 28200 | Acc.: 59.58%\n",
      "Epoch: 41/50 | Iter.: 28300 | Acc.: 62.90%\n",
      "Epoch: 41/50 | Iter.: 28400 | Acc.: 58.86%\n",
      "Epoch: 41/50 | Iter.: 28500 | Acc.: 63.44%\n",
      "Epoch: 41/50 | Iter.: 28600 | Acc.: 58.66%\n",
      "Epoch: 41/50 | Iter.: 28700 | Acc.: 63.70%\n",
      "Epoch: 41/50 | Iter.: 28800 | Acc.: 62.92%\n",
      "Epoch: 42/50 | Iter.: 28900 | Acc.: 64.28%\n",
      "Epoch: 42/50 | Iter.: 29000 | Acc.: 64.38%\n",
      "Epoch: 42/50 | Iter.: 29100 | Acc.: 63.48%\n",
      "Epoch: 42/50 | Iter.: 29200 | Acc.: 61.18%\n",
      "Epoch: 42/50 | Iter.: 29300 | Acc.: 61.14%\n",
      "Epoch: 42/50 | Iter.: 29400 | Acc.: 61.86%\n",
      "Epoch: 42/50 | Iter.: 29500 | Acc.: 57.24%\n",
      "Epoch: 43/50 | Iter.: 29600 | Acc.: 63.42%\n",
      "Epoch: 43/50 | Iter.: 29700 | Acc.: 64.22%\n",
      "Epoch: 43/50 | Iter.: 29800 | Acc.: 63.78%\n",
      "Epoch: 43/50 | Iter.: 29900 | Acc.: 64.56%\n",
      "Epoch: 43/50 | Iter.: 30000 | Acc.: 58.76%\n",
      "Epoch: 43/50 | Iter.: 30100 | Acc.: 63.42%\n",
      "Epoch: 43/50 | Iter.: 30200 | Acc.: 50.48%\n",
      "Epoch: 44/50 | Iter.: 30300 | Acc.: 60.88%\n",
      "Epoch: 44/50 | Iter.: 30400 | Acc.: 62.94%\n",
      "Epoch: 44/50 | Iter.: 30500 | Acc.: 63.36%\n",
      "Epoch: 44/50 | Iter.: 30600 | Acc.: 63.56%\n",
      "Epoch: 44/50 | Iter.: 30700 | Acc.: 64.66%\n",
      "Epoch: 44/50 | Iter.: 30800 | Acc.: 61.90%\n",
      "Epoch: 44/50 | Iter.: 30900 | Acc.: 64.28%\n",
      "Epoch: 45/50 | Iter.: 31000 | Acc.: 58.74%\n",
      "Epoch: 45/50 | Iter.: 31100 | Acc.: 59.98%\n",
      "Epoch: 45/50 | Iter.: 31200 | Acc.: 63.34%\n",
      "Epoch: 45/50 | Iter.: 31300 | Acc.: 60.54%\n",
      "Epoch: 45/50 | Iter.: 31400 | Acc.: 62.38%\n",
      "Epoch: 45/50 | Iter.: 31500 | Acc.: 63.30%\n",
      "Epoch: 45/50 | Iter.: 31600 | Acc.: 61.02%\n",
      "Epoch: 46/50 | Iter.: 31700 | Acc.: 62.70%\n",
      "Epoch: 46/50 | Iter.: 31800 | Acc.: 64.12%\n",
      "Epoch: 46/50 | Iter.: 31900 | Acc.: 62.88%\n",
      "Epoch: 46/50 | Iter.: 32000 | Acc.: 62.74%\n",
      "Epoch: 46/50 | Iter.: 32100 | Acc.: 62.74%\n",
      "Epoch: 46/50 | Iter.: 32200 | Acc.: 64.20%\n",
      "Epoch: 46/50 | Iter.: 32300 | Acc.: 62.10%\n",
      "Epoch: 47/50 | Iter.: 32400 | Acc.: 51.02%\n",
      "Epoch: 47/50 | Iter.: 32500 | Acc.: 64.34%\n",
      "Epoch: 47/50 | Iter.: 32600 | Acc.: 63.44%\n",
      "Epoch: 47/50 | Iter.: 32700 | Acc.: 61.70%\n",
      "Epoch: 47/50 | Iter.: 32800 | Acc.: 63.08%\n",
      "Epoch: 47/50 | Iter.: 32900 | Acc.: 63.48%\n",
      "Epoch: 47/50 | Iter.: 33000 | Acc.: 58.08%\n",
      "Epoch: 48/50 | Iter.: 33100 | Acc.: 61.44%\n",
      "Epoch: 48/50 | Iter.: 33200 | Acc.: 60.98%\n",
      "Epoch: 48/50 | Iter.: 33300 | Acc.: 63.98%\n",
      "Epoch: 48/50 | Iter.: 33400 | Acc.: 61.26%\n",
      "Epoch: 48/50 | Iter.: 33500 | Acc.: 63.66%\n",
      "Epoch: 48/50 | Iter.: 33600 | Acc.: 62.64%\n",
      "Epoch: 48/50 | Iter.: 33700 | Acc.: 63.72%\n",
      "Epoch: 49/50 | Iter.: 33800 | Acc.: 62.76%\n",
      "Epoch: 49/50 | Iter.: 33900 | Acc.: 58.90%\n",
      "Epoch: 49/50 | Iter.: 34000 | Acc.: 64.56%\n",
      "Epoch: 49/50 | Iter.: 34100 | Acc.: 64.54%\n",
      "Epoch: 49/50 | Iter.: 34200 | Acc.: 59.18%\n",
      "Epoch: 49/50 | Iter.: 34300 | Acc.: 56.80%\n",
      "Epoch: 49/50 | Iter.: 34400 | Acc.: 60.18%\n",
      "Epoch: 50/50 | Iter.: 34500 | Acc.: 58.22%\n",
      "Epoch: 50/50 | Iter.: 34600 | Acc.: 54.88%\n",
      "Epoch: 50/50 | Iter.: 34700 | Acc.: 64.34%\n",
      "Epoch: 50/50 | Iter.: 34800 | Acc.: 63.18%\n",
      "Epoch: 50/50 | Iter.: 34900 | Acc.: 63.12%\n",
      "Epoch: 50/50 | Iter.: 35000 | Acc.: 59.78%\n",
      "Epoch: 50/50 | Iter.: 35100 | Acc.: 64.58%\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for data, targets in iter(train_loader):\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        net.train()\n",
    "        #spk_rec, _ = forward_pass(net, num_steps, data)\n",
    "        spk_rec, _ = net(data)\n",
    "\n",
    "        # initialize the loss & sum over time\n",
    "        loss = loss_fn_rate(spk_rec, targets)\n",
    "\n",
    "        # Gradient calculation + weight update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if counter % 100 == 0:\n",
    "            test_acc = batch_accuracy(valid_loader, net, num_steps)\n",
    "            print(f'Epoch: {epoch+1}/{num_epochs} | Iter.: {counter} | Acc.: {test_acc*100:.2f}%')\n",
    "        counter += 1\n",
    "\n",
    "        if( test_acc > min_acc ):\n",
    "            best_acc_epoch = epoch\n",
    "            best_model_state = net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "580f3efc-0012-4dab-8af1-2cfd1f41fb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model from epoch [49]\n",
      "Test Acc: 63.58%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Load model from epoch [{best_acc_epoch}]')\n",
    "net.load_state_dict(best_model_state)\n",
    "\n",
    "# Test set forward pass\n",
    "test_acc = batch_accuracy(test_loader, net, num_steps)\n",
    "print(f\"Test Acc: {test_acc * 100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5662c201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hwkang/jupyter/root\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
