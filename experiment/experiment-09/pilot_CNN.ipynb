{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "path_root = '/home/hwkang/jupyter/root'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(path_root)\n",
    "sys.path.append(os.path.join(path_root,'utility/'))\n",
    "sys.path.append(os.path.join(path_root,'model/'))\n",
    "sys.path.append(os.path.join(path_root,'experiment/experiment-09/'))\n",
    "from models import CNN\n",
    "\n",
    "from utility.statistic import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNormalize:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, data):\n",
    "        vmax, vmin = data.max(), data.min()\n",
    "        return (data-vmin)/(vmax-vmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(train_loader, net):\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        acc = 0\n",
    "        net.eval()\n",
    "\n",
    "        train_loader = iter(train_loader)\n",
    "        all_labels = []\n",
    "        all_predictions = []\n",
    "        for data, targets in train_loader:\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "            #spk_rec, _ = forward_pass(net, num_steps, data)\n",
    "            #spk_rec, _ = net(data)\n",
    "            spk_rec = net(data)\n",
    "\n",
    "            #acc += SF.accuracy_rate(spk_rec, targets) * spk_rec.size(1)\n",
    "            #total += spk_rec.size(1)\n",
    "\n",
    "            predicted_value, predicted_class = torch.max(spk_rec, dim=1)\n",
    "            all_labels.extend(targets.detach().cpu().numpy())\n",
    "            all_predictions.extend(predicted_class.detach().cpu().numpy())\n",
    "\n",
    "    acc, _, _, _ = get_classification_metrics(all_labels, all_predictions, 'weighted')\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), MyNormalize()])\n",
    "train_dataset = datasets.CIFAR10(root='/home/hwkang/jupyter/root/dataset', train=True, transform=transform, download=False)\n",
    "test_dataset = datasets.CIFAR10(root='/home/hwkang/jupyter/root/dataset', train=False, transform=transform, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 훈련 데이터셋과 검증 데이터셋으로 분할\n",
    "dataset_size = len(train_dataset)\n",
    "train_size = int(0.9 * dataset_size)\n",
    "valid_size = dataset_size - train_size\n",
    "train_dataset, valid_dataset = random_split(train_dataset, [train_size, valid_size])\n",
    "##*\n",
    "\n",
    "### 데이터로더 준비\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_steps=50\n",
    "\n",
    "# Model\n",
    "#net = Net(num_steps=num_steps, beta=0.9, spike_grad=surrogate.atan())\n",
    "net = CNN()\n",
    "net = net.to(device)\n",
    "\n",
    "# Epoch\n",
    "num_epochs = 50\n",
    "\n",
    "# Loss func.\n",
    "#loss_fn_rate = SF.ce_rate_loss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optim.\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3, betas=(0.9, 0.999))\n",
    "\n",
    "# Util.\n",
    "loss_hist = []\n",
    "test_acc_hist = []\n",
    "counter = 0\n",
    "min_acc = 0.0\n",
    "best_acc_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hwkang/jupyter/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50 | Iter.: 0 | Acc.: 10.58%\n",
      "Epoch: 1/50 | Iter.: 100 | Acc.: 41.10%\n",
      "Epoch: 1/50 | Iter.: 200 | Acc.: 42.90%\n",
      "Epoch: 1/50 | Iter.: 300 | Acc.: 48.34%\n",
      "Epoch: 1/50 | Iter.: 400 | Acc.: 52.24%\n",
      "Epoch: 1/50 | Iter.: 500 | Acc.: 46.90%\n",
      "Epoch: 1/50 | Iter.: 600 | Acc.: 55.08%\n",
      "Epoch: 1/50 | Iter.: 700 | Acc.: 51.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hwkang/jupyter/venv/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/50 | Iter.: 800 | Acc.: 54.58%\n",
      "Epoch: 2/50 | Iter.: 900 | Acc.: 58.44%\n",
      "Epoch: 2/50 | Iter.: 1000 | Acc.: 57.66%\n",
      "Epoch: 2/50 | Iter.: 1100 | Acc.: 54.42%\n",
      "Epoch: 2/50 | Iter.: 1200 | Acc.: 56.60%\n",
      "Epoch: 2/50 | Iter.: 1300 | Acc.: 56.54%\n",
      "Epoch: 2/50 | Iter.: 1400 | Acc.: 57.48%\n",
      "Epoch: 3/50 | Iter.: 1500 | Acc.: 60.00%\n",
      "Epoch: 3/50 | Iter.: 1600 | Acc.: 59.58%\n",
      "Epoch: 3/50 | Iter.: 1700 | Acc.: 60.46%\n",
      "Epoch: 3/50 | Iter.: 1800 | Acc.: 54.46%\n",
      "Epoch: 3/50 | Iter.: 1900 | Acc.: 62.22%\n",
      "Epoch: 3/50 | Iter.: 2000 | Acc.: 58.58%\n",
      "Epoch: 3/50 | Iter.: 2100 | Acc.: 62.22%\n",
      "Epoch: 4/50 | Iter.: 2200 | Acc.: 61.06%\n",
      "Epoch: 4/50 | Iter.: 2300 | Acc.: 55.06%\n",
      "Epoch: 4/50 | Iter.: 2400 | Acc.: 57.02%\n",
      "Epoch: 4/50 | Iter.: 2500 | Acc.: 62.24%\n",
      "Epoch: 4/50 | Iter.: 2600 | Acc.: 56.00%\n",
      "Epoch: 4/50 | Iter.: 2700 | Acc.: 62.80%\n",
      "Epoch: 4/50 | Iter.: 2800 | Acc.: 63.60%\n",
      "Epoch: 5/50 | Iter.: 2900 | Acc.: 63.10%\n",
      "Epoch: 5/50 | Iter.: 3000 | Acc.: 63.06%\n",
      "Epoch: 5/50 | Iter.: 3100 | Acc.: 62.18%\n",
      "Epoch: 5/50 | Iter.: 3200 | Acc.: 66.98%\n",
      "Epoch: 5/50 | Iter.: 3300 | Acc.: 66.44%\n",
      "Epoch: 5/50 | Iter.: 3400 | Acc.: 62.44%\n",
      "Epoch: 5/50 | Iter.: 3500 | Acc.: 66.14%\n",
      "Epoch: 6/50 | Iter.: 3600 | Acc.: 68.04%\n",
      "Epoch: 6/50 | Iter.: 3700 | Acc.: 65.78%\n",
      "Epoch: 6/50 | Iter.: 3800 | Acc.: 63.60%\n",
      "Epoch: 6/50 | Iter.: 3900 | Acc.: 61.72%\n",
      "Epoch: 6/50 | Iter.: 4000 | Acc.: 65.04%\n",
      "Epoch: 6/50 | Iter.: 4100 | Acc.: 67.68%\n",
      "Epoch: 6/50 | Iter.: 4200 | Acc.: 57.06%\n",
      "Epoch: 7/50 | Iter.: 4300 | Acc.: 65.52%\n",
      "Epoch: 7/50 | Iter.: 4400 | Acc.: 66.40%\n",
      "Epoch: 7/50 | Iter.: 4500 | Acc.: 68.18%\n",
      "Epoch: 7/50 | Iter.: 4600 | Acc.: 68.92%\n",
      "Epoch: 7/50 | Iter.: 4700 | Acc.: 66.86%\n",
      "Epoch: 7/50 | Iter.: 4800 | Acc.: 68.70%\n",
      "Epoch: 7/50 | Iter.: 4900 | Acc.: 61.14%\n",
      "Epoch: 8/50 | Iter.: 5000 | Acc.: 66.70%\n",
      "Epoch: 8/50 | Iter.: 5100 | Acc.: 59.60%\n",
      "Epoch: 8/50 | Iter.: 5200 | Acc.: 66.34%\n",
      "Epoch: 8/50 | Iter.: 5300 | Acc.: 67.86%\n",
      "Epoch: 8/50 | Iter.: 5400 | Acc.: 69.84%\n",
      "Epoch: 8/50 | Iter.: 5500 | Acc.: 66.52%\n",
      "Epoch: 8/50 | Iter.: 5600 | Acc.: 62.90%\n",
      "Epoch: 9/50 | Iter.: 5700 | Acc.: 67.32%\n",
      "Epoch: 9/50 | Iter.: 5800 | Acc.: 69.70%\n",
      "Epoch: 9/50 | Iter.: 5900 | Acc.: 68.52%\n",
      "Epoch: 9/50 | Iter.: 6000 | Acc.: 64.02%\n",
      "Epoch: 9/50 | Iter.: 6100 | Acc.: 68.38%\n",
      "Epoch: 9/50 | Iter.: 6200 | Acc.: 68.40%\n",
      "Epoch: 9/50 | Iter.: 6300 | Acc.: 65.10%\n",
      "Epoch: 10/50 | Iter.: 6400 | Acc.: 67.02%\n",
      "Epoch: 10/50 | Iter.: 6500 | Acc.: 64.62%\n",
      "Epoch: 10/50 | Iter.: 6600 | Acc.: 71.42%\n",
      "Epoch: 10/50 | Iter.: 6700 | Acc.: 67.64%\n",
      "Epoch: 10/50 | Iter.: 6800 | Acc.: 67.16%\n",
      "Epoch: 10/50 | Iter.: 6900 | Acc.: 70.14%\n",
      "Epoch: 10/50 | Iter.: 7000 | Acc.: 70.16%\n",
      "Epoch: 11/50 | Iter.: 7100 | Acc.: 68.20%\n",
      "Epoch: 11/50 | Iter.: 7200 | Acc.: 69.82%\n",
      "Epoch: 11/50 | Iter.: 7300 | Acc.: 64.80%\n",
      "Epoch: 11/50 | Iter.: 7400 | Acc.: 67.00%\n",
      "Epoch: 11/50 | Iter.: 7500 | Acc.: 68.82%\n",
      "Epoch: 11/50 | Iter.: 7600 | Acc.: 66.30%\n",
      "Epoch: 11/50 | Iter.: 7700 | Acc.: 67.74%\n",
      "Epoch: 12/50 | Iter.: 7800 | Acc.: 58.68%\n",
      "Epoch: 12/50 | Iter.: 7900 | Acc.: 68.86%\n",
      "Epoch: 12/50 | Iter.: 8000 | Acc.: 69.86%\n",
      "Epoch: 12/50 | Iter.: 8100 | Acc.: 69.00%\n",
      "Epoch: 12/50 | Iter.: 8200 | Acc.: 65.50%\n",
      "Epoch: 12/50 | Iter.: 8300 | Acc.: 69.80%\n",
      "Epoch: 12/50 | Iter.: 8400 | Acc.: 70.16%\n",
      "Epoch: 13/50 | Iter.: 8500 | Acc.: 65.52%\n",
      "Epoch: 13/50 | Iter.: 8600 | Acc.: 68.06%\n",
      "Epoch: 13/50 | Iter.: 8700 | Acc.: 68.22%\n",
      "Epoch: 13/50 | Iter.: 8800 | Acc.: 71.64%\n",
      "Epoch: 13/50 | Iter.: 8900 | Acc.: 71.06%\n",
      "Epoch: 13/50 | Iter.: 9000 | Acc.: 68.56%\n",
      "Epoch: 13/50 | Iter.: 9100 | Acc.: 70.48%\n",
      "Epoch: 14/50 | Iter.: 9200 | Acc.: 67.14%\n",
      "Epoch: 14/50 | Iter.: 9300 | Acc.: 63.48%\n",
      "Epoch: 14/50 | Iter.: 9400 | Acc.: 68.78%\n",
      "Epoch: 14/50 | Iter.: 9500 | Acc.: 70.60%\n",
      "Epoch: 14/50 | Iter.: 9600 | Acc.: 71.10%\n",
      "Epoch: 14/50 | Iter.: 9700 | Acc.: 70.20%\n",
      "Epoch: 14/50 | Iter.: 9800 | Acc.: 71.06%\n",
      "Epoch: 15/50 | Iter.: 9900 | Acc.: 59.64%\n",
      "Epoch: 15/50 | Iter.: 10000 | Acc.: 66.90%\n",
      "Epoch: 15/50 | Iter.: 10100 | Acc.: 72.60%\n",
      "Epoch: 15/50 | Iter.: 10200 | Acc.: 68.70%\n",
      "Epoch: 15/50 | Iter.: 10300 | Acc.: 69.78%\n",
      "Epoch: 15/50 | Iter.: 10400 | Acc.: 70.42%\n",
      "Epoch: 15/50 | Iter.: 10500 | Acc.: 67.68%\n",
      "Epoch: 16/50 | Iter.: 10600 | Acc.: 70.20%\n",
      "Epoch: 16/50 | Iter.: 10700 | Acc.: 68.04%\n",
      "Epoch: 16/50 | Iter.: 10800 | Acc.: 70.80%\n",
      "Epoch: 16/50 | Iter.: 10900 | Acc.: 70.44%\n",
      "Epoch: 16/50 | Iter.: 11000 | Acc.: 70.94%\n",
      "Epoch: 16/50 | Iter.: 11100 | Acc.: 69.78%\n",
      "Epoch: 16/50 | Iter.: 11200 | Acc.: 70.48%\n",
      "Epoch: 17/50 | Iter.: 11300 | Acc.: 70.72%\n",
      "Epoch: 17/50 | Iter.: 11400 | Acc.: 70.02%\n",
      "Epoch: 17/50 | Iter.: 11500 | Acc.: 72.08%\n",
      "Epoch: 17/50 | Iter.: 11600 | Acc.: 68.36%\n",
      "Epoch: 17/50 | Iter.: 11700 | Acc.: 65.92%\n",
      "Epoch: 17/50 | Iter.: 11800 | Acc.: 70.74%\n",
      "Epoch: 17/50 | Iter.: 11900 | Acc.: 71.44%\n",
      "Epoch: 18/50 | Iter.: 12000 | Acc.: 71.66%\n",
      "Epoch: 18/50 | Iter.: 12100 | Acc.: 72.20%\n",
      "Epoch: 18/50 | Iter.: 12200 | Acc.: 71.88%\n",
      "Epoch: 18/50 | Iter.: 12300 | Acc.: 69.92%\n",
      "Epoch: 18/50 | Iter.: 12400 | Acc.: 69.56%\n",
      "Epoch: 18/50 | Iter.: 12500 | Acc.: 68.40%\n",
      "Epoch: 18/50 | Iter.: 12600 | Acc.: 70.22%\n",
      "Epoch: 19/50 | Iter.: 12700 | Acc.: 66.98%\n",
      "Epoch: 19/50 | Iter.: 12800 | Acc.: 71.76%\n",
      "Epoch: 19/50 | Iter.: 12900 | Acc.: 71.20%\n",
      "Epoch: 19/50 | Iter.: 13000 | Acc.: 71.02%\n",
      "Epoch: 19/50 | Iter.: 13100 | Acc.: 69.10%\n",
      "Epoch: 19/50 | Iter.: 13200 | Acc.: 70.26%\n",
      "Epoch: 19/50 | Iter.: 13300 | Acc.: 70.84%\n",
      "Epoch: 20/50 | Iter.: 13400 | Acc.: 70.16%\n",
      "Epoch: 20/50 | Iter.: 13500 | Acc.: 71.94%\n",
      "Epoch: 20/50 | Iter.: 13600 | Acc.: 70.16%\n",
      "Epoch: 20/50 | Iter.: 13700 | Acc.: 70.62%\n",
      "Epoch: 20/50 | Iter.: 13800 | Acc.: 70.58%\n",
      "Epoch: 20/50 | Iter.: 13900 | Acc.: 73.06%\n",
      "Epoch: 20/50 | Iter.: 14000 | Acc.: 73.30%\n",
      "Epoch: 21/50 | Iter.: 14100 | Acc.: 70.16%\n",
      "Epoch: 21/50 | Iter.: 14200 | Acc.: 73.10%\n",
      "Epoch: 21/50 | Iter.: 14300 | Acc.: 70.54%\n",
      "Epoch: 21/50 | Iter.: 14400 | Acc.: 73.00%\n",
      "Epoch: 21/50 | Iter.: 14500 | Acc.: 73.42%\n",
      "Epoch: 21/50 | Iter.: 14600 | Acc.: 69.08%\n",
      "Epoch: 21/50 | Iter.: 14700 | Acc.: 70.10%\n",
      "Epoch: 22/50 | Iter.: 14800 | Acc.: 71.20%\n",
      "Epoch: 22/50 | Iter.: 14900 | Acc.: 62.78%\n",
      "Epoch: 22/50 | Iter.: 15000 | Acc.: 71.56%\n",
      "Epoch: 22/50 | Iter.: 15100 | Acc.: 72.60%\n",
      "Epoch: 22/50 | Iter.: 15200 | Acc.: 71.46%\n",
      "Epoch: 22/50 | Iter.: 15300 | Acc.: 73.18%\n",
      "Epoch: 22/50 | Iter.: 15400 | Acc.: 70.14%\n",
      "Epoch: 23/50 | Iter.: 15500 | Acc.: 66.90%\n",
      "Epoch: 23/50 | Iter.: 15600 | Acc.: 72.10%\n",
      "Epoch: 23/50 | Iter.: 15700 | Acc.: 72.24%\n",
      "Epoch: 23/50 | Iter.: 15800 | Acc.: 69.20%\n",
      "Epoch: 23/50 | Iter.: 15900 | Acc.: 70.98%\n",
      "Epoch: 23/50 | Iter.: 16000 | Acc.: 73.12%\n",
      "Epoch: 23/50 | Iter.: 16100 | Acc.: 72.28%\n",
      "Epoch: 24/50 | Iter.: 16200 | Acc.: 70.98%\n",
      "Epoch: 24/50 | Iter.: 16300 | Acc.: 67.66%\n",
      "Epoch: 24/50 | Iter.: 16400 | Acc.: 69.70%\n",
      "Epoch: 24/50 | Iter.: 16500 | Acc.: 71.22%\n",
      "Epoch: 24/50 | Iter.: 16600 | Acc.: 67.56%\n",
      "Epoch: 24/50 | Iter.: 16700 | Acc.: 72.96%\n",
      "Epoch: 24/50 | Iter.: 16800 | Acc.: 70.00%\n",
      "Epoch: 25/50 | Iter.: 16900 | Acc.: 72.64%\n",
      "Epoch: 25/50 | Iter.: 17000 | Acc.: 64.56%\n",
      "Epoch: 25/50 | Iter.: 17100 | Acc.: 72.04%\n",
      "Epoch: 25/50 | Iter.: 17200 | Acc.: 65.88%\n",
      "Epoch: 25/50 | Iter.: 17300 | Acc.: 72.42%\n",
      "Epoch: 25/50 | Iter.: 17400 | Acc.: 73.46%\n",
      "Epoch: 25/50 | Iter.: 17500 | Acc.: 72.48%\n",
      "Epoch: 26/50 | Iter.: 17600 | Acc.: 65.12%\n",
      "Epoch: 26/50 | Iter.: 17700 | Acc.: 73.84%\n",
      "Epoch: 26/50 | Iter.: 17800 | Acc.: 70.86%\n",
      "Epoch: 26/50 | Iter.: 17900 | Acc.: 68.18%\n",
      "Epoch: 26/50 | Iter.: 18000 | Acc.: 68.12%\n",
      "Epoch: 26/50 | Iter.: 18100 | Acc.: 72.20%\n",
      "Epoch: 26/50 | Iter.: 18200 | Acc.: 72.48%\n",
      "Epoch: 26/50 | Iter.: 18300 | Acc.: 69.46%\n",
      "Epoch: 27/50 | Iter.: 18400 | Acc.: 72.74%\n",
      "Epoch: 27/50 | Iter.: 18500 | Acc.: 73.74%\n",
      "Epoch: 27/50 | Iter.: 18600 | Acc.: 69.56%\n",
      "Epoch: 27/50 | Iter.: 18700 | Acc.: 74.32%\n",
      "Epoch: 27/50 | Iter.: 18800 | Acc.: 61.82%\n",
      "Epoch: 27/50 | Iter.: 18900 | Acc.: 69.78%\n",
      "Epoch: 27/50 | Iter.: 19000 | Acc.: 72.74%\n",
      "Epoch: 28/50 | Iter.: 19100 | Acc.: 66.38%\n",
      "Epoch: 28/50 | Iter.: 19200 | Acc.: 68.68%\n",
      "Epoch: 28/50 | Iter.: 19300 | Acc.: 71.48%\n",
      "Epoch: 28/50 | Iter.: 19400 | Acc.: 70.28%\n",
      "Epoch: 28/50 | Iter.: 19500 | Acc.: 69.42%\n",
      "Epoch: 28/50 | Iter.: 19600 | Acc.: 72.46%\n",
      "Epoch: 28/50 | Iter.: 19700 | Acc.: 70.66%\n",
      "Epoch: 29/50 | Iter.: 19800 | Acc.: 70.58%\n",
      "Epoch: 29/50 | Iter.: 19900 | Acc.: 67.62%\n",
      "Epoch: 29/50 | Iter.: 20000 | Acc.: 74.20%\n",
      "Epoch: 29/50 | Iter.: 20100 | Acc.: 73.22%\n",
      "Epoch: 29/50 | Iter.: 20200 | Acc.: 60.58%\n",
      "Epoch: 29/50 | Iter.: 20300 | Acc.: 68.50%\n",
      "Epoch: 29/50 | Iter.: 20400 | Acc.: 72.52%\n",
      "Epoch: 30/50 | Iter.: 20500 | Acc.: 68.94%\n",
      "Epoch: 30/50 | Iter.: 20600 | Acc.: 72.08%\n",
      "Epoch: 30/50 | Iter.: 20700 | Acc.: 72.38%\n",
      "Epoch: 30/50 | Iter.: 20800 | Acc.: 72.16%\n",
      "Epoch: 30/50 | Iter.: 20900 | Acc.: 71.98%\n",
      "Epoch: 30/50 | Iter.: 21000 | Acc.: 73.16%\n",
      "Epoch: 30/50 | Iter.: 21100 | Acc.: 73.64%\n",
      "Epoch: 31/50 | Iter.: 21200 | Acc.: 73.78%\n",
      "Epoch: 31/50 | Iter.: 21300 | Acc.: 72.48%\n",
      "Epoch: 31/50 | Iter.: 21400 | Acc.: 72.54%\n",
      "Epoch: 31/50 | Iter.: 21500 | Acc.: 71.42%\n",
      "Epoch: 31/50 | Iter.: 21600 | Acc.: 72.76%\n",
      "Epoch: 31/50 | Iter.: 21700 | Acc.: 73.24%\n",
      "Epoch: 31/50 | Iter.: 21800 | Acc.: 73.66%\n",
      "Epoch: 32/50 | Iter.: 21900 | Acc.: 72.30%\n",
      "Epoch: 32/50 | Iter.: 22000 | Acc.: 72.28%\n",
      "Epoch: 32/50 | Iter.: 22100 | Acc.: 73.24%\n",
      "Epoch: 32/50 | Iter.: 22200 | Acc.: 71.04%\n",
      "Epoch: 32/50 | Iter.: 22300 | Acc.: 72.18%\n",
      "Epoch: 32/50 | Iter.: 22400 | Acc.: 70.90%\n",
      "Epoch: 32/50 | Iter.: 22500 | Acc.: 72.94%\n",
      "Epoch: 33/50 | Iter.: 22600 | Acc.: 72.22%\n",
      "Epoch: 33/50 | Iter.: 22700 | Acc.: 70.28%\n",
      "Epoch: 33/50 | Iter.: 22800 | Acc.: 73.54%\n",
      "Epoch: 33/50 | Iter.: 22900 | Acc.: 74.06%\n",
      "Epoch: 33/50 | Iter.: 23000 | Acc.: 70.68%\n",
      "Epoch: 33/50 | Iter.: 23100 | Acc.: 72.34%\n",
      "Epoch: 33/50 | Iter.: 23200 | Acc.: 74.16%\n",
      "Epoch: 34/50 | Iter.: 23300 | Acc.: 74.00%\n",
      "Epoch: 34/50 | Iter.: 23400 | Acc.: 72.46%\n",
      "Epoch: 34/50 | Iter.: 23500 | Acc.: 73.34%\n",
      "Epoch: 34/50 | Iter.: 23600 | Acc.: 71.80%\n",
      "Epoch: 34/50 | Iter.: 23700 | Acc.: 72.24%\n",
      "Epoch: 34/50 | Iter.: 23800 | Acc.: 68.84%\n",
      "Epoch: 34/50 | Iter.: 23900 | Acc.: 72.22%\n",
      "Epoch: 35/50 | Iter.: 24000 | Acc.: 71.78%\n",
      "Epoch: 35/50 | Iter.: 24100 | Acc.: 73.04%\n",
      "Epoch: 35/50 | Iter.: 24200 | Acc.: 74.00%\n",
      "Epoch: 35/50 | Iter.: 24300 | Acc.: 73.02%\n",
      "Epoch: 35/50 | Iter.: 24400 | Acc.: 68.94%\n",
      "Epoch: 35/50 | Iter.: 24500 | Acc.: 73.16%\n",
      "Epoch: 35/50 | Iter.: 24600 | Acc.: 73.84%\n",
      "Epoch: 36/50 | Iter.: 24700 | Acc.: 73.48%\n",
      "Epoch: 36/50 | Iter.: 24800 | Acc.: 68.34%\n",
      "Epoch: 36/50 | Iter.: 24900 | Acc.: 73.62%\n",
      "Epoch: 36/50 | Iter.: 25000 | Acc.: 73.94%\n",
      "Epoch: 36/50 | Iter.: 25100 | Acc.: 68.88%\n",
      "Epoch: 36/50 | Iter.: 25200 | Acc.: 70.52%\n",
      "Epoch: 36/50 | Iter.: 25300 | Acc.: 72.44%\n",
      "Epoch: 37/50 | Iter.: 25400 | Acc.: 74.36%\n",
      "Epoch: 37/50 | Iter.: 25500 | Acc.: 72.46%\n",
      "Epoch: 37/50 | Iter.: 25600 | Acc.: 74.60%\n",
      "Epoch: 37/50 | Iter.: 25700 | Acc.: 74.20%\n",
      "Epoch: 37/50 | Iter.: 25800 | Acc.: 71.16%\n",
      "Epoch: 37/50 | Iter.: 25900 | Acc.: 70.90%\n",
      "Epoch: 37/50 | Iter.: 26000 | Acc.: 71.70%\n",
      "Epoch: 38/50 | Iter.: 26100 | Acc.: 71.42%\n",
      "Epoch: 38/50 | Iter.: 26200 | Acc.: 74.30%\n",
      "Epoch: 38/50 | Iter.: 26300 | Acc.: 71.92%\n",
      "Epoch: 38/50 | Iter.: 26400 | Acc.: 72.44%\n",
      "Epoch: 38/50 | Iter.: 26500 | Acc.: 73.68%\n",
      "Epoch: 38/50 | Iter.: 26600 | Acc.: 73.98%\n",
      "Epoch: 38/50 | Iter.: 26700 | Acc.: 74.52%\n",
      "Epoch: 39/50 | Iter.: 26800 | Acc.: 73.72%\n",
      "Epoch: 39/50 | Iter.: 26900 | Acc.: 71.56%\n",
      "Epoch: 39/50 | Iter.: 27000 | Acc.: 69.98%\n",
      "Epoch: 39/50 | Iter.: 27100 | Acc.: 73.48%\n",
      "Epoch: 39/50 | Iter.: 27200 | Acc.: 73.14%\n",
      "Epoch: 39/50 | Iter.: 27300 | Acc.: 73.22%\n",
      "Epoch: 39/50 | Iter.: 27400 | Acc.: 74.50%\n",
      "Epoch: 40/50 | Iter.: 27500 | Acc.: 69.40%\n",
      "Epoch: 40/50 | Iter.: 27600 | Acc.: 72.74%\n",
      "Epoch: 40/50 | Iter.: 27700 | Acc.: 74.36%\n",
      "Epoch: 40/50 | Iter.: 27800 | Acc.: 74.88%\n",
      "Epoch: 40/50 | Iter.: 27900 | Acc.: 69.98%\n",
      "Epoch: 40/50 | Iter.: 28000 | Acc.: 73.22%\n",
      "Epoch: 40/50 | Iter.: 28100 | Acc.: 58.22%\n",
      "Epoch: 41/50 | Iter.: 28200 | Acc.: 69.72%\n",
      "Epoch: 41/50 | Iter.: 28300 | Acc.: 67.74%\n",
      "Epoch: 41/50 | Iter.: 28400 | Acc.: 73.48%\n",
      "Epoch: 41/50 | Iter.: 28500 | Acc.: 71.32%\n",
      "Epoch: 41/50 | Iter.: 28600 | Acc.: 72.00%\n",
      "Epoch: 41/50 | Iter.: 28700 | Acc.: 71.32%\n",
      "Epoch: 41/50 | Iter.: 28800 | Acc.: 72.46%\n",
      "Epoch: 42/50 | Iter.: 28900 | Acc.: 69.78%\n",
      "Epoch: 42/50 | Iter.: 29000 | Acc.: 74.26%\n",
      "Epoch: 42/50 | Iter.: 29100 | Acc.: 74.04%\n",
      "Epoch: 42/50 | Iter.: 29200 | Acc.: 71.74%\n",
      "Epoch: 42/50 | Iter.: 29300 | Acc.: 72.86%\n",
      "Epoch: 42/50 | Iter.: 29400 | Acc.: 73.50%\n",
      "Epoch: 42/50 | Iter.: 29500 | Acc.: 71.78%\n",
      "Epoch: 43/50 | Iter.: 29600 | Acc.: 73.92%\n",
      "Epoch: 43/50 | Iter.: 29700 | Acc.: 71.86%\n",
      "Epoch: 43/50 | Iter.: 29800 | Acc.: 67.22%\n",
      "Epoch: 43/50 | Iter.: 29900 | Acc.: 71.50%\n",
      "Epoch: 43/50 | Iter.: 30000 | Acc.: 72.20%\n",
      "Epoch: 43/50 | Iter.: 30100 | Acc.: 73.38%\n",
      "Epoch: 43/50 | Iter.: 30200 | Acc.: 73.44%\n",
      "Epoch: 44/50 | Iter.: 30300 | Acc.: 73.78%\n",
      "Epoch: 44/50 | Iter.: 30400 | Acc.: 72.88%\n",
      "Epoch: 44/50 | Iter.: 30500 | Acc.: 74.70%\n",
      "Epoch: 44/50 | Iter.: 30600 | Acc.: 72.06%\n",
      "Epoch: 44/50 | Iter.: 30700 | Acc.: 74.06%\n",
      "Epoch: 44/50 | Iter.: 30800 | Acc.: 72.32%\n",
      "Epoch: 44/50 | Iter.: 30900 | Acc.: 73.36%\n",
      "Epoch: 45/50 | Iter.: 31000 | Acc.: 73.60%\n",
      "Epoch: 45/50 | Iter.: 31100 | Acc.: 74.88%\n",
      "Epoch: 45/50 | Iter.: 31200 | Acc.: 69.22%\n",
      "Epoch: 45/50 | Iter.: 31300 | Acc.: 73.14%\n",
      "Epoch: 45/50 | Iter.: 31400 | Acc.: 71.94%\n",
      "Epoch: 45/50 | Iter.: 31500 | Acc.: 73.14%\n",
      "Epoch: 45/50 | Iter.: 31600 | Acc.: 70.58%\n",
      "Epoch: 46/50 | Iter.: 31700 | Acc.: 74.20%\n",
      "Epoch: 46/50 | Iter.: 31800 | Acc.: 71.18%\n",
      "Epoch: 46/50 | Iter.: 31900 | Acc.: 71.40%\n",
      "Epoch: 46/50 | Iter.: 32000 | Acc.: 74.28%\n",
      "Epoch: 46/50 | Iter.: 32100 | Acc.: 74.22%\n",
      "Epoch: 46/50 | Iter.: 32200 | Acc.: 73.58%\n",
      "Epoch: 46/50 | Iter.: 32300 | Acc.: 70.64%\n",
      "Epoch: 47/50 | Iter.: 32400 | Acc.: 69.62%\n",
      "Epoch: 47/50 | Iter.: 32500 | Acc.: 73.88%\n",
      "Epoch: 47/50 | Iter.: 32600 | Acc.: 67.74%\n",
      "Epoch: 47/50 | Iter.: 32700 | Acc.: 74.92%\n",
      "Epoch: 47/50 | Iter.: 32800 | Acc.: 73.92%\n",
      "Epoch: 47/50 | Iter.: 32900 | Acc.: 73.50%\n",
      "Epoch: 47/50 | Iter.: 33000 | Acc.: 73.36%\n",
      "Epoch: 48/50 | Iter.: 33100 | Acc.: 73.36%\n",
      "Epoch: 48/50 | Iter.: 33200 | Acc.: 71.58%\n",
      "Epoch: 48/50 | Iter.: 33300 | Acc.: 71.26%\n",
      "Epoch: 48/50 | Iter.: 33400 | Acc.: 73.06%\n",
      "Epoch: 48/50 | Iter.: 33500 | Acc.: 72.74%\n",
      "Epoch: 48/50 | Iter.: 33600 | Acc.: 74.04%\n",
      "Epoch: 48/50 | Iter.: 33700 | Acc.: 75.04%\n",
      "Epoch: 49/50 | Iter.: 33800 | Acc.: 73.26%\n",
      "Epoch: 49/50 | Iter.: 33900 | Acc.: 71.66%\n",
      "Epoch: 49/50 | Iter.: 34000 | Acc.: 71.28%\n",
      "Epoch: 49/50 | Iter.: 34100 | Acc.: 71.90%\n",
      "Epoch: 49/50 | Iter.: 34200 | Acc.: 73.50%\n",
      "Epoch: 49/50 | Iter.: 34300 | Acc.: 73.84%\n",
      "Epoch: 49/50 | Iter.: 34400 | Acc.: 75.18%\n",
      "Epoch: 50/50 | Iter.: 34500 | Acc.: 68.96%\n",
      "Epoch: 50/50 | Iter.: 34600 | Acc.: 74.42%\n",
      "Epoch: 50/50 | Iter.: 34700 | Acc.: 73.08%\n",
      "Epoch: 50/50 | Iter.: 34800 | Acc.: 74.82%\n",
      "Epoch: 50/50 | Iter.: 34900 | Acc.: 74.88%\n",
      "Epoch: 50/50 | Iter.: 35000 | Acc.: 68.00%\n",
      "Epoch: 50/50 | Iter.: 35100 | Acc.: 74.66%\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for data, targets in iter(train_loader):\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        net.train()\n",
    "        #spk_rec, _ = forward_pass(net, num_steps, data)\n",
    "        #spk_rec, _ = net(data)\n",
    "        spk_rec = net(data)\n",
    "\n",
    "        # initialize the loss & sum over time\n",
    "        loss = criterion(spk_rec, targets)\n",
    "\n",
    "        # Gradient calculation + weight update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if counter % 100 == 0:\n",
    "            #test_acc = batch_accuracy(valid_loader, net, num_steps)\n",
    "            test_acc = batch_accuracy(valid_loader, net)\n",
    "            print(f'Epoch: {epoch+1}/{num_epochs} | Iter.: {counter} | Acc.: {test_acc*100:.2f}%')\n",
    "        counter += 1\n",
    "\n",
    "        if( test_acc > min_acc ):\n",
    "            best_acc_epoch = epoch\n",
    "            best_model_state = net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model from epoch [49]\n",
      "Test Acc: 72.22%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Load model from epoch [{best_acc_epoch}]')\n",
    "net.load_state_dict(best_model_state)\n",
    "\n",
    "# Test set forward pass\n",
    "#test_acc = batch_accuracy(test_loader, net, num_steps)\n",
    "test_acc = batch_accuracy(test_loader, net)\n",
    "print(f\"Test Acc: {test_acc * 100:.2f}%\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
