{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e36d2a4d-4b0a-4325-8662-348977501ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorchs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR #학습률 스케줄링\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet50, resnet101\n",
    "\n",
    "# SnnTorchs\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "#from snntorch import backprop\n",
    "from snntorch import functional as SF\n",
    "from snntorch import utils\n",
    "from snntorch import spikeplot as splt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad67df21-8de8-4277-a620-a8e641d6a806",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingResNet101_2(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(SpikingResNet101_2, self).__init__()\n",
    "\n",
    "        # Copy the initial layers before Conv2_x\n",
    "        self.conv1 = original_model.conv1\n",
    "        self.bn1 = original_model.bn1\n",
    "        self.maxpool = original_model.maxpool\n",
    "\n",
    "        # Modify the Conv2_x layer group by replacing ReLU with snn.Leaky\n",
    "        self.layer1 = self.modify_layer_group(original_model.layer1)\n",
    "\n",
    "        \"\"\"\n",
    "        for i, block in enumerate(original_model.layer1):\n",
    "            for j, layer in enumerate(block.children()):\n",
    "        \"\"\"     \n",
    "\n",
    "        # Copy the remaining layers without modification\n",
    "        self.layer2 = original_model.layer2\n",
    "        self.layer3 = original_model.layer3\n",
    "        self.layer4 = original_model.layer4\n",
    "        self.avgpool = original_model.avgpool\n",
    "        self.fc = original_model.fc\n",
    "\n",
    "    def modify_layer_group(self, layer_group):\n",
    "        for idx, layer in enumerate(layer_group):\n",
    "            if isinstance(layer.relu, nn.ReLU):\n",
    "                layer_group[idx].relu = snn.Leaky(beta=0.9, spike_grad=surrogate.fast_sigmoid(), init_hidden=True)\n",
    "        return layer_group\n",
    "\n",
    "    def reset_mem(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, snn.Leaky):\n",
    "                module.reset_mem()\n",
    "    \n",
    "    def forward(self, x, num_steps=10):\n",
    "        # Forward pass through the modified network\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        # Forward pass through modified layer1 (Conv2_x)\n",
    "        spk_rec = []\n",
    "        self.reset_mem()\n",
    "        for step in range(num_steps):\n",
    "            spk= self.layer1(x)\n",
    "            spk_rec.append(spk)\n",
    "\n",
    "        # Average over time steps\n",
    "        x = torch.mean(torch.stack(spk_rec), dim=0)\n",
    "\n",
    "        # Forward pass through the remaining layers\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb155fb2-73c6-4f9b-8d1e-6397b8106daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model = resnet101(weights=None, num_classes=10)\n",
    "model = SpikingResNet101_2(original_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99ff190a-e1e5-4b6f-8813-8487c3127cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn((1,3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aebb70c-1369-4f38-ae72-95c5aeb8eda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcd6a2c0-ac34-409f-9d8d-619e142a7336",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a0c74a8-f872-4a51-b917-a5288ca07361",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.randn((1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7230f21e-a72c-4c7a-883a-39ee7c7b910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ff20bb7-44b1-47f6-8c26-43e6ce44b60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(outputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "240010a9-83bd-415e-8a3d-b04a796303c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1680ef5e-75ac-4750-999f-2035012fbdae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
